{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (env search)",
      "name": "py-dku-venv-search",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.6.14",
      "name": "python",
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "dkuGit": {
      "lastInteraction": 0
    },
    "creator": "admin",
    "associatedRecipe": "compute_idx_zalando",
    "createdOn": 1637774554406,
    "hide_input": false,
    "creationTag": {
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1637774554406,
      "versionNumber": 0
    },
    "customFields": {},
    "tags": [
      "recipe-editor"
    ],
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%config IPCompleter.use_jedi \u003d False"
      ],
      "outputs": []
    },
    {
      "execution_count": 11,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu \nimport inference\nfrom elasticsearch import Elasticsearch\nfrom elasticsearch.helpers import bulk"
      ],
      "outputs": []
    },
    {
      "execution_count": 5,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_path \u003d dataiku.Folder(\"UKTXMoc0\").get_path()"
      ],
      "outputs": []
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model \u003d inference.model_fn(model_path)"
      ],
      "outputs": []
    },
    {
      "execution_count": 8,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_details_by_image_path \u003d dataiku.Dataset(\"image_details_by_image_path\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 12,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "es \u003d Elasticsearch()"
      ],
      "outputs": []
    },
    {
      "execution_count": 10,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def make_feature_vec(row, model):\n    data \u003d row[\u0027description_concat\u0027]\n    feature_vec \u003d inference.predict_fn(data, model)\n    return feature_vec"
      ],
      "outputs": []
    },
    {
      "execution_count": 25,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sample_row \u003d image_details_by_image_path_df.head(1).to_dict(orient\u003d\u0027records\u0027)[0]"
      ],
      "outputs": []
    },
    {
      "execution_count": 26,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_dim \u003d len(make_feature_vec(row, model))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--- Inference time: 0.35622191429138184 seconds ---\n"
        }
      ]
    },
    {
      "execution_count": 31,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# create elasticsearch Index\nif es.indices.exists(index\u003d\u0027idx_zalando\u0027):\n    es.indices.delete(index\u003d\u0027idx_zalando\u0027)\n    \ncreate_query \u003d {\n    \"mappings\": {\n        \"properties\": {\n            \"zalando_nlu_vector\": {\n                \"type\": \"dense_vector\",\n                \"dims\": model_dim\n            }\n        }\n    }\n}\n\nes.indices.create(index\u003d\u0027idx_zalando\u0027, **create_query)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "{\u0027acknowledged\u0027: True, \u0027shards_acknowledged\u0027: True, \u0027index\u0027: \u0027idx_zalando\u0027}"
          },
          "execution_count": 31
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_embeddings():\n    for row in image_details_by_image_path.iter_rows():\n        embeddings \u003d make_feature_vec(row, model)\n        row[\u0027zalando_nlu_vector\u0027] \u003d embeddings\n        yield row"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulk(es, get_embeddings())"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\nimage_details_by_image_path \u003d dataiku.Dataset(\"image_details_by_image_path\")\nimage_details_by_image_path_df \u003d image_details_by_image_path.get_dataframe()\n\n\n# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n\nidx_zalando_df \u003d image_details_by_image_path_df # For this sample code, simply copy input to output\n\n\n# Write recipe outputs\nidx_zalando \u003d dataiku.Dataset(\"idx_zalando\")\nidx_zalando.write_with_schema(idx_zalando_df)"
      ],
      "outputs": []
    }
  ]
}