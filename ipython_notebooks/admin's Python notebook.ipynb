{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (env search)",
      "name": "py-dku-venv-search",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.6.14",
      "name": "python",
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "creator": "admin",
    "createdOn": 1637693823727,
    "hide_input": false,
    "customFields": {},
    "tags": [],
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%config IPCompleter.use_jedi \u003d False"
      ],
      "outputs": []
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku"
      ],
      "outputs": []
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import inference"
      ],
      "outputs": []
    },
    {
      "execution_count": 5,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_folder \u003d dataiku.Folder(\"UKTXMoc0\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 6,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model \u003d inference.model_fn(model_folder.get_path())"
      ],
      "outputs": []
    },
    {
      "execution_count": 10,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data \u003d \"blue dress\""
      ],
      "outputs": []
    },
    {
      "execution_count": 9,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inference.predict_fn()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "PreTrainedTokenizerFast(name_or_path\u003d\u0027/Users/davidcarlson/Library/dss/design/managed_folders/FASHIONSEARCH/UKTXMoc0\u0027, vocab_size\u003d30522, model_max_len\u003d512, is_fast\u003dTrue, padding_side\u003d\u0027right\u0027, special_tokens\u003d{\u0027unk_token\u0027: \u0027[UNK]\u0027, \u0027sep_token\u0027: \u0027[SEP]\u0027, \u0027pad_token\u0027: \u0027[PAD]\u0027, \u0027cls_token\u0027: \u0027[CLS]\u0027, \u0027mask_token\u0027: \u0027[MASK]\u0027})"
          },
          "execution_count": 9
        }
      ]
    },
    {
      "execution_count": 8,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model[\u0027model\u0027]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "DistilBertModel(\n  (embeddings): Embeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx\u003d0)\n    (position_embeddings): Embedding(512, 768)\n    (LayerNorm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n    (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n  )\n  (transformer): Transformer(\n    (layer): ModuleList(\n      (0): TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (q_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (k_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (v_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (out_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n        (ffn): FFN(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (lin1): Linear(in_features\u003d768, out_features\u003d3072, bias\u003dTrue)\n          (lin2): Linear(in_features\u003d3072, out_features\u003d768, bias\u003dTrue)\n        )\n        (output_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n      )\n      (1): TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (q_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (k_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (v_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (out_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n        (ffn): FFN(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (lin1): Linear(in_features\u003d768, out_features\u003d3072, bias\u003dTrue)\n          (lin2): Linear(in_features\u003d3072, out_features\u003d768, bias\u003dTrue)\n        )\n        (output_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n      )\n      (2): TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (q_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (k_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (v_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (out_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n        (ffn): FFN(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (lin1): Linear(in_features\u003d768, out_features\u003d3072, bias\u003dTrue)\n          (lin2): Linear(in_features\u003d3072, out_features\u003d768, bias\u003dTrue)\n        )\n        (output_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n      )\n      (3): TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (q_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (k_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (v_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (out_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n        (ffn): FFN(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (lin1): Linear(in_features\u003d768, out_features\u003d3072, bias\u003dTrue)\n          (lin2): Linear(in_features\u003d3072, out_features\u003d768, bias\u003dTrue)\n        )\n        (output_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n      )\n      (4): TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (q_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (k_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (v_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (out_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n        (ffn): FFN(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (lin1): Linear(in_features\u003d768, out_features\u003d3072, bias\u003dTrue)\n          (lin2): Linear(in_features\u003d3072, out_features\u003d768, bias\u003dTrue)\n        )\n        (output_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n      )\n      (5): TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (q_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (k_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (v_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n          (out_lin): Linear(in_features\u003d768, out_features\u003d768, bias\u003dTrue)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n        (ffn): FFN(\n          (dropout): Dropout(p\u003d0.1, inplace\u003dFalse)\n          (lin1): Linear(in_features\u003d768, out_features\u003d3072, bias\u003dTrue)\n          (lin2): Linear(in_features\u003d3072, out_features\u003d768, bias\u003dTrue)\n        )\n        (output_layer_norm): LayerNorm((768,), eps\u003d1e-12, elementwise_affine\u003dTrue)\n      )\n    )\n  )\n)"
          },
          "execution_count": 8
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: load a DSS dataset as a Pandas dataframe\nmydataset \u003d dataiku.Dataset(\"mydataset\")\nmydataset_df \u003d mydataset.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}